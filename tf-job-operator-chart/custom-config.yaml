# In this file you can specify a custom configuration for TfJob, such as specific driver mounts
# and environment variable.
# Note that configurations for GCE and Azure (ACS, acs-engine, AKS) are already available: simply set cloud=gce
# or cloud=azure in values.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: tf-job-operator-config
  namespace: default
data:
  controller_config_file.yaml: |
    grpcServerFilePath: /opt/mlkube/grpc_tensorflow_server/grpc_tensorflow_server.py
    accelerators:
      alpha.kubernetes.io/nvidia-gpu: 
        # These are all the Volumes and VolumeMounts that should be added to any pod requesting 
        # a resource of type "alpha.kubernetes.io/nvidia-gpu"
        volumes:  
          - name: nvidia-libraries
            mountPath: /usr/local/nvidia/lib64 # This path is special; it is expected to be present in `/etc/ld.so.conf` inside the container image.
            hostPath: /home/kubernetes/bin/nvidia/lib
          - name: nvidia-debug-tools # optional
            mountPath: /usr/local/bin/nvidia
            hostPath: /home/kubernetes/bin/nvidia/bin
        # These are all the environment variables that should be added to any pod requesting 
        # a resource of type "alpha.kubernetes.io/nvidia-gpu", such as LD_LIBRARY_PATH
        envVars:  